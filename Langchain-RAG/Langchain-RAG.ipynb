{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac377704-5c10-459b-8aca-59896fd339a4",
   "metadata": {},
   "source": [
    "RAG - Retrieval Augmented Generation\n",
    "RAG is the technique that enhances language models by combining them with a retrieval system. It allows the model to access and utilize external knowledge when generating responses.\n",
    "\n",
    "-Load\n",
    "-Split\n",
    "-Embed\n",
    "-Store (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805e1440-1705-4887-911e-c88be541a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.19\n",
      "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\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(langchain.__version__)\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "openai_api_key=os.getenv(\"openai_api_key\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found.\")\n",
    "\n",
    "langchain_api_key=os.getenv(\"langchain_api_key\")\n",
    "if not langchain_api_key:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY not found.\")\n",
    "\n",
    "print(openai_api_key)\n",
    "print(langchain_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3df5ec6-541c-4823-882e-db21bcd3d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=openai_api_key\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=langchain_api_key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Langchain-RAG\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac0dbc8b-e145-4e9a-982d-3d51f490435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Good morning! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_13eed4fce1', 'finish_reason': 'stop', 'logprobs': None}, id='run-fbb068a8-42ff-47d1-9748-f6b9a2896e30-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_response=llm.invoke(\"Hi, good morning\")\n",
    "\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd363dd-600f-43f9-aacc-93be2f8a9cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning! How can I assist you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parsers=StrOutputParser()\n",
    "output_parsers.invoke(llm_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07385f65-861e-4ea9-b773-c4cf56fa30c8",
   "metadata": {},
   "source": [
    "Structure Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce02c69a-d42b-4f59-a6ae-49b48044eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MobileReview(BaseModel):\n",
    "    phone_model:str=Field(description=\"Name and model of the phone\")\n",
    "    rating: float=Field(description=\"Overall rating out of 5\")\n",
    "    pros:List[str]=Field(description=\"List of positive aspects\")\n",
    "    cons:List[str]=Field(description=\"List of negative aspects\")\n",
    "    summary:str=Field(description=\"Brief summary of the review\")\n",
    "\n",
    "review_text=\"\"\"\n",
    "iPhone 16 Review (4.5/5)\n",
    "The iPhone 16 refines Apple’s formula with better performance, improved battery life, and subtle design tweaks. While not a game-changer, it’s a solid upgrade for those with older models.\n",
    "\n",
    "Pros:\n",
    "A18 Bionic chip delivers top-tier performance\n",
    "Longer battery life with optimized efficiency\n",
    "Brighter and smoother display with ProMotion 2.0\n",
    "Camera enhancements for low-light photography\n",
    "\n",
    "Cons:\n",
    "Minimal design changes from the iPhone 15\n",
    "Still no USB-C fast charging improvements\n",
    "High price, especially for base storage\n",
    "\n",
    "Verdict: If you're coming from an iPhone 14 or older, it's a great upgrade. But if you have an iPhone 15, you might want to wait for next year.\n",
    "\"\"\"\n",
    "\n",
    "structured_llm = llm.with_structured_output(MobileReview)\n",
    "output=structured_llm.invoke(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70cb502c-fa5a-4d5d-8778-d3c51a7cedc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileReview(phone_model='iPhone 16', rating=4.5, pros=['A18 Bionic chip delivers top-tier performance', 'Longer battery life with optimized efficiency', 'Brighter and smoother display with ProMotion 2.0', 'Camera enhancements for low-light photography'], cons=['Minimal design changes from the iPhone 15', 'Still no USB-C fast charging improvements', 'High price, especially for base storage'], summary='The iPhone 16 refines Apple’s formula with better performance, improved battery life, and subtle design tweaks. While not a game-changer, it’s a solid upgrade for those with older models.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfae92-c33c-4bf2-aa38-60c9d55be312",
   "metadata": {},
   "source": [
    "LLM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c106127-afa8-4103-98c7-9cf58bfa29a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a framework designed to facilitate the development of applications using Large Language Models (LLMs). It provides a structured way to integrate LLMs with various components and tools, allowing developers to create complex applications that leverage the capabilities of language models more efficiently.\\n\\nHere are some key aspects of LangChain:\\n\\n1. **Components**: LangChain consists of several components that can work together. These include LLMs, prompts, chains, agents, and memory. Each of these components serves a specific purpose and can be combined to create powerful applications.\\n\\n2. **LLMs**: LangChain supports multiple LLMs, allowing developers to choose the best model for their application needs. This includes popular models from providers like OpenAI, Hugging Face, and others.\\n\\n3. **Chains**: Chains are sequences of calls where the output of one call can be used as the input for the next. This allows for the construction of complex workflows by linking simple processing steps together.\\n\\n4. **Agents**: Agents are capable of making decisions based on the inputs they receive and can dynamically choose which actions to take. This includes selecting which tools to use or which chain to execute based on contextual cues.\\n\\n5. **Memory**: LangChain can maintain state over interactions, providing memory capabilities. This allows applications to remember past interactions or context, which enhances user experience and leads to more relevant and personalized responses.\\n\\n6. **Integrations**: LangChain is designed to work seamlessly with other software and tools, making it easy to integrate with existing systems. This includes natural language processing tools, databases, APIs, and more.\\n\\n7. **Use Cases**: LangChain can be applied to a wide range of applications, including chatbots, virtual assistants, content generation, summarization tools, question-answering systems, and much more.\\n\\nBy providing this structured approach, LangChain simplifies the process of building applications that utilize the power of LLMs, enabling developers to focus on crafting unique functionalities rather than getting bogged down by the underlying complexities of the models.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 412, 'prompt_tokens': 25, 'total_tokens': 437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_13eed4fce1', 'finish_reason': 'stop', 'logprobs': None}, id='run-25a42dd1-48e1-4a53-bff6-4b8610efc1ce-0', usage_metadata={'input_tokens': 25, 'output_tokens': 412, 'total_tokens': 437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"You are a smart engineer.\")\n",
    "human_message = HumanMessage(content=\"Tell me about LLM in Langchain\")\n",
    "llm.invoke([system_message,human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7e6c5-dfa3-4773-9bed-991fbfaf8f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
